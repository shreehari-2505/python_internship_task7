# ğŸ¯ Support Vector Machines (SVM) â€“ Binary Classification on Breast Cancer Dataset

## ğŸ“Œ Objective

This project is part of myÂ **AI & ML Internship â€“ Task 7**.  
The goal is toÂ **implement Support Vector Machines for binary classification**Â to predict whether a tumor isÂ **Malignant (0)**Â orÂ **Benign (1)**Â using theÂ **Breast Cancer Wisconsin dataset**. Focus on linear and RBF kernels, decision boundary visualization, hyperparameter tuning, and cross-validation.

---

## ğŸ›  Tools & Libraries Used

|Tool / Library|Purpose|
|---|---|
|**Python**|Core programming language|
|**Pandas**|Data loading and wrangling (though minimal here)|
|**NumPy**|Numerical computations, array operations|
|**Matplotlib/Seaborn**|Data visualization and plotting decision boundaries|
|**Scikit-learn**|Dataset loading, preprocessing, SVM modeling, evaluation, and tuning|
|**Joblib**|Model serialization|
|**Google Colab**|Notebook execution environment|

---

## ğŸ”„ Workflow â€“ Step-by-Step Logic Flow

Text-based flowchart showing entire process:

[Start]  
â†“  
Load dataset (`datasets.load_breast_cancer()`)  
â†“  
Initial inspection â†’ shape, features, target distribution  
â†“  
Split into train/test (80/20) withÂ `train_test_split`  
â†“  
Standardize features withÂ `StandardScaler`  
â†“  
Reduce to 2D for visualization usingÂ `PCA(n_components=2)`  
â†“  
Train Linear SVM (`SVC(kernel='linear')`) and RBF SVM (`SVC(kernel='rbf')`)  
â†“  
Predict on test set and evaluate (accuracy, classification report)  
â†“  
Visualize 2D decision boundaries with meshgrid plotting  
â†“  
Tune hyperparameters (C, gamma) viaÂ `GridSearchCV`Â with 5-fold CV  
â†“  
Evaluate tuned model â†’ confusion matrix, CV scores  
â†“  
Interpret support vectors and save model/outputs with Joblib/CSV  
â†“  
[End]

---

## ğŸ§ª Steps Performed in Detail

## 1ï¸âƒ£Â **Data Loading**

- Dataset:Â **Breast Cancer Wisconsin (Diagnostic) Data Set**
    
- Loaded using:Â `cancer = datasets.load_breast_cancer(); X = cancer.data; y = cancer.target`
    

## 2ï¸âƒ£Â **Data Preparation**

- Split data:Â `train_test_split(X, y, test_size=0.2, random_state=42)`
    
- Scaled features:Â `StandardScaler().fit_transform(X_train)`
    
- Dimensionality reduction for visualization:Â `PCA(n_components=2).fit_transform(X_train_scaled)`
    

## 3ï¸âƒ£Â **Model Training**

- Trained Linear SVM:Â `SVC(kernel='linear').fit(X_train_scaled, y_train)`
    
- Trained RBF SVM:Â `SVC(kernel='rbf').fit(X_train_scaled, y_train)`
    
- Trained 2D versions for boundary plotting.
    

## 4ï¸âƒ£Â **Predictions & Evaluation**

- Predictions withÂ `.predict(X_test_scaled)`.
    
- Metrics: Accuracy, classification report, confusion matrix.
    
- Cross-validation:Â `cross_val_score`Â for robustness.
    

## 5ï¸âƒ£Â **Visualization**

- Plotted decision boundaries using meshgrid and contourf for linear and RBF kernels on 2D PCA data.
    
- Added scatterplot of training points with class hues.
    

## 6ï¸âƒ£Â **Hyperparameter Tuning**

- Grid search:Â `GridSearchCV`Â with params {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]} and 5-fold CV.
    
- Selected best model and evaluated on test set.
    

## 7ï¸âƒ£Â **Interpretation**

- Counted support vectors:Â `len(best_svm.support_)`.
    
- Plotted confusion matrix heatmap.
    

## 8ï¸âƒ£Â **Model Saving**

- Saved model:Â `joblib.dump(best_svm, 'svm_model.pkl')`
    
- Exported predictions:Â `pd.DataFrame(...).to_csv('predictions.csv')`
    

---

## ğŸ“š Vocabulary of Functions & Commands Used

|Command / Function|Purpose|
|---|---|
|`datasets.load_breast_cancer()`|Loads built-in breast cancer dataset|
|`train_test_split(X, y, test_size, random_state)`|Splits dataset into train and test sets|
|`StandardScaler()`|Scales features to mean=0, std=1|
|`.fit_transform(data)`|Fits scaler to data and transforms|
|`.transform(data)`|Transforms new data using fitted scaler|
|`PCA(n_components=2)`|Reduces dimensionality to 2D for visualization|
|`SVC(kernel='linear' or 'rbf')`|Defines SVM classifier with specified kernel|
|`.fit(X_train, y_train)`|Trains SVM model on training set|
|`.predict(X_test)`|Predicts labels for new data|
|`accuracy_score(y_true, y_pred)`|Computes prediction accuracy|
|`classification_report(y_true, y_pred)`|Generates precision, recall, f1-score|
|`confusion_matrix(y_true, y_pred)`|Creates confusion matrix|
|`cross_val_score(model, X, y, cv)`|Performs k-fold cross-validation|
|`GridSearchCV(estimator, param_grid, cv)`|Tunes hyperparameters with grid search and CV|
|`np.meshgrid(x, y)`|Creates grid for plotting decision boundaries|
|`plt.contourf(xx, yy, Z)`|Plots filled contours for boundaries|
|`sns.scatterplot(x, y, hue)`|Plots scattered points with class colors|
|`joblib.dump(object, filename)`|Saves Python object to file|
|`pd.DataFrame().to_csv(filename)`|Exports DataFrame to CSV|

---

## ğŸ“Š Key Insights

- SVM excels in high-dimensional spaces via margin maximization and the kernel trick, with RBF handling non-linear separability better than linear (achieved ~98% accuracy post-tuning).
    
- Hyperparameter tuning (C for regularization, gamma for RBF spread) is crucial to balance underfitting/overfitting; cross-validation ensures generalizability.
    
- Visualization of decision boundaries highlights how RBF creates curved separations, critical for non-linear data like cancer features.
    
- Support vectors (~100-200) define the model; fewer indicate efficient classification. SVM's robustness to outliers makes it ideal for medical datasets.
    

---

## âœ Prepared By

ğŸ“„ README prepared byÂ **Perplexity AI**
